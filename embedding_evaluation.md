# üìÑ **PDF Embedding Evaluation Report**

## **1. Overview**

This document summarizes the evaluation of three different PDF chunking and embedding strategies:

* **Fixed-size chunking**
* **Semantic chunking**
* **Hybrid (semantic + sliding window)**

The goal was to determine which chunking method provides the best retrieval quality when used with **OpenAI embeddings** and **ChromaDB**.

All tests were run against a well-structured PDF containing headings, lists, paragraphs, and a few tables.

---

## **2. Chunk Counts**

The total number of chunks generated by each method:

```
Fixed-size: 88
Semantic:   67
Hybrid:     169
```

### üìä Chunk Count Comparison

```
Chunks
170 |                          ‚ñà‚ñà‚ñà‚ñà Hybrid (169)
150 |
130 |
110 |           ‚ñà‚ñà‚ñà‚ñà Fixed (88)
 90 |
 70 |      ‚ñà‚ñà‚ñà Semantic (67)
 50 |
  0 +---------------------------------
        Semantic   Fixed   Hybrid
```

**Observation:**
Semantic chunking produced the *fewest* chunks, making it the most efficient.
Hybrid chunking produced ~2.5√ó more chunks than semantic.

---

## **3. Retrieval Accuracy**

Metrics captured:

* **Hit@1, Hit@3, Hit@5**
* **MRR (Mean Reciprocal Rank)**
* **nDCG (Normalized Discounted Cumulative Gain)**

### ‚úî All strategies achieved **Hit@5 = 100%**

### ‚úî Fixed-size and Semantic achieved **Hit@1 = 100%**

### ‚úî Hybrid had **one Hit@1 miss (87.5% success)**

---

## **4. MRR Comparison**

Mean Reciprocal Rank indicates the position of the correct answer.

### üìà MRR Comparison

```
1.00 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Fixed-size
     | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Semantic
0.95 |
0.90 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Hybrid (0.94 average)
0.85 |
     +---------------------------------
        Semantic   Fixed   Hybrid
```

**Observation:**

* Semantic and Fixed-size scored **perfect MRR = 1.0**
* Hybrid scored slightly lower (**one query returned the correct chunk at rank 2**)

---

## **5. nDCG Comparison**

nDCG evaluates quality of ranking across all retrieved documents.

### üìä nDCG (avg)

```
1.00 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Fixed-size
0.98 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Semantic
0.94 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Hybrid
0.90 |
     +-------------------------
        Semantic Fixed Hybrid
```

**Observation:**
Hybrid had slightly more ranking noise due to overlapping windowed chunks.

---

## **6. Key Findings**

### **1. Semantic Chunking is the Best Overall**

* Perfect retrieval accuracy
* Lowest number of chunks ‚Üí cheapest to embed
* Strong rankings across all queries
* Most efficient + highest quality combination

### **2. Fixed-size Chunking Performs Similarly Well**

* Also perfect retrieval performance
* Slightly more chunks than semantic
* Good fallback if semantic parsing is not available

### **3. Hybrid Chunking is Not Beneficial for This PDF**

* 2.5√ó more chunks (significantly higher cost)
* Slightly worse Hit@1 and MRR
* Good for dense legal or scientific PDFs, but unnecessary here

---

## **7. Final Outcome**

| Strategy       | Retrieval Quality | Efficiency | Best Use Case                 |
| -------------- | ----------------- | ---------- | ----------------------------- |
| **Semantic**   | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Best)      | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê      | Structured PDFs |
| **Fixed-size** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê             | ‚≠ê‚≠ê‚≠ê‚≠ê       | Simpler fallback              |
| **Hybrid**     | ‚≠ê‚≠ê‚≠ê‚≠ê              | ‚≠ê‚≠ê         | Dense technical or legal docs |